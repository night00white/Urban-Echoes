# -*- coding: utf-8 -*-
"""architectural-style-recognition.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JTIvf_-yEUw22a2_xp6wu7CM-9f__JYs

## Import
"""

# Commented out IPython magic to ensure Python compatibility.
# ensure that any edits to libraries you make are reloaded here automatically
# %reload_ext autoreload
# %autoreload 2

# ensure that any charts or images displayed are shown in this notebook
# %matplotlib inline

from google.colab import files
import os

# fastai V1 library which sits on top of Pytorch 1.0
from fastai.vision import *

!pip install fastai --upgrade

# to avoid warning of PyTorch
import warnings
warnings.filterwarnings("ignore", category=UserWarning, module="torch.nn.functional")

"""## Download dataset from Kaggle"""

# ! {sys.executable} -m pip install kaggle --upgrade

"""To be able to download data from Kaggle you have to provide an API token, which you can find on your Kaggle account. In case of doubt find more information in the following link:

https://github.com/Kaggle/kaggle-api#:~:text=To%20use%20the%20Kaggle%20API,file%20containing%20your%20API%20credentials
"""

###uploaded = files.upload()

###os.listdir()

###! mkdir -p ~/.kaggle/
###! mv kaggle.json ~/.kaggle/

###!pip install fastcore

###from pathlib import Path

###path = Path('https://www.kaggle.com/datasets/dumitrux/architectural-styles-dataset/code') / 'architecture'
###path.mkdir(parents=True, exist_ok=True)
###print (path)

###from fastcore.foundation import Config

# If architecture is a variable, ensure it is defined in your code
# If architecture is supposed to be a string (folder name), use '/ 'architecture''
#path = Config().data_path / 'architecture'
#path.mkdir(parents=True, exist_ok=True)

## Access the data path for Kaggle datasets
#path = Config.data_path() /architecture
#path.mkdir(parents=True, exist_ok=True)

###path = config.data_path()/'architecture'
###path.mkdir(parents=True, exist_ok=True)
###ath

###! kaggle datasets download -d wwymak/architecture-dataset

# bigger dataset
# ! kaggle datasets download -d dumitrux/architectural-styles-dataset

# ! unzip -q -n architectural-styles-dataset.zip -d {path}

###os.listdir(www.kaggle.com/datasets/dumitrux/architectural-styles-dataset/code/architecture)

###! unzip -q -n architecture-dataset.zip -d {path}

"""## Looking at the data

We are going to use the Architecture dataset by Zhe Xu, which features 25 architecture styles. Our model will need to learn to differentiate between these 25 distinct categories. According to their paper, the best accuracy they could get in 2014 was nearly 70% accuracy.
"""

###os.listdir('/root/.fastai/data/architecture/arcDataset')

# bigger dataset
# path = '/root/.fastai/data/architecture/architectural-styles-dataset'

"""The first thing we do when we approach a problem is to take a look at the data. We always need to understand very well what the problem is and what the data looks like before we can figure out how to solve it. Taking a look at the data means understanding how the data directories are structured, what the labels are and what some sample images look like.

In this particular dataset, labels are stored in the folder name which containt images of each class. We will need to extract them to be able to classify the images into the correct categories. The fastai library has a function made for this, `ImageDataBunch.from_folder`.
"""

from google.colab import drive
drive.mount('/content/drive')

#change this path to your DPT Segmentation folder
os.chdir('/content/drive/Shareddrives/T+ ML/Group_ML_T+2023/style')

import numpy as np

# Set a random seed to ensure reproducibility
np.random.seed(42)

# Now you can use NumPy functions and objects

# to not get different results everytime and to be sure that the improvement
# has not been only been chance
#np.random.seed(42)

!pip install fastai

import fastai
print(fastai.__version__)

from fastai.vision.all import *

path = '/content/drive/Shareddrives/T+ ML/Group_ML_T+2023/style'

tfms = aug_transforms(do_flip=True, flip_vert=False, max_rotate=10.0, max_zoom=1.1,
                      max_lighting=0.2, max_warp=0.2, p_affine=0.75, p_lighting=0.75)

dls = ImageDataLoaders.from_folder(path,
                                   train=".",
                                   valid_pct=0.2,
                                   item_tfms=Resize(460),
                                   batch_tfms=[*tfms, Normalize.from_stats(*imagenet_stats)],
                                   bs=64,
                                   num_workers=4)

from fastai.vision.augment import aug_transforms

tfms = aug_transforms(do_flip=True, flip_vert=False, max_rotate=10.0, max_zoom=1.1, max_lighting=0.2, max_warp=0.2, p_affine=0.75, p_lighting=0.75)

###data = ImageDataBunch.from_folder(path, train=".", valid_pct=0.2,
        ###ds_tfms=tfms, size=224, num_workers=4, padding_mode='reflection', bs=64).normalize(imagenet_stats)

dls.show_batch(nrows=3, figsize=(9, 9))

###data.show_batch(rows=3, figsize=(9, 9))

# Number of classes
num_classes = len(dls.vocab)
# Classes
classes = dls.vocab
# Length of training dataset
len_train_ds = len(dls.train_ds)
# Length of validation dataset
len_valid_ds = len(dls.valid_ds)

classes, num_classes, len_train_ds, len_valid_ds

###data.classes, data.c, len(data.train_ds), len(data.valid_ds)

"""#### Data augmentation

The `get_transforms` fucntion helped us to get more images to train, in this case we have 9588 images instead of 4979 from the original dataset.

This is achived making some changes to the images and treat them like news images.

Flipping (just horizontal), zooming, light, rotate, etc.
"""

def _plot(i,j,ax):
    x,y = data.train_ds[3]
    x.show(ax, y=y)

import matplotlib.pyplot as plt

def plot_multi(i, im, r, c, figsize=None):
    "Plot multiple images"
    fig, axs = plt.subplots(r, c, figsize=figsize)
    axs = axs.flatten()
    for i, ax in enumerate(axs): _plot(i, im, ax)
    plt.show()

def _plot(i, im, ax):
    img = im[i]  # or however you get the i-th image
    ax.imshow(img)
    ax.axis('off')

###plot_multi(_plot, 3, 3, figsize=(8,8))

"""## Training: resnet34

Now we will start training our model. We will use a [convolutional neural network](https://cs231n.github.io/convolutional-networks/) and a fully connected head with a single hidden layer as a classifier.
The model that we are building will take images as input and will output the predicted probability for each of the categories (in this case, it will have 25 outputs).

### Training

fit_one_cycle(n)

n: number of epochs

epochs: looking at every input once. n too big, loot of parameters and high lr maybe overfiting

Things that can go wrong



*   Learning rate (LR) too high: huge valid_loss
*   Learning rate (LR) too low: valid_loss barerly change during epochs
*   Too few epochs
*   Too many epochs: valid_loss grows during epochs
"""

# learn = cnn_learner(data, models.resnet34, metrics=[accuracy, error_rate]).to_fp16()
# float point of 16 bits to make the training faster. It has not worked on this case

learn = cnn_learner(dls, resnet34, metrics=[accuracy, error_rate])

###learn = cnn_learner(data, models.resnet34, metrics=[accuracy, error_rate])
# doc(cnn_learner)

# We will train for 4 epochs (4 cycles through all our data)
learn.fit_one_cycle(4)

from fastai.vision.all import *
path = "/content/mydrive/Shareddrives/T+ ML/Group_ML_T+2023/style"
dls = ImageDataLoaders.from_folder('/content/drive/Shareddrives/T+ ML/Group_ML_T+2023/style', train=".", valid_pct=0.2, item_tfms=Resize(460), batch_tfms=aug_transforms(size=224))
learn = cnn_learner(dls, resnet34, metrics=accuracy)
print(dls)

learn.save('stage-1-resnet34')

"""### Results

Let's see what results we have got.

We will first see which were the categories that the model most confused with one another. We will try to see if what the model predicted was reasonable or not.

Furthermore, when we plot the confusion matrix, we can see that the distribution is heavily skewed: the model makes the same mistakes over and over again but it rarely confuses other categories. This suggests that it just finds it difficult to distinguish some specific categories between each other; this is normal behaviour.
"""

interp = ClassificationInterpretation.from_learner(learn)

from fastai.vision.all import *

# Load data, create DataLoaders, and train model...

# Create an interpreter
interp = ClassificationInterpretation.from_learner(learn)

# Find most confused classes
confused = interp.most_confused(min_val=5)
print(confused)

###interp.most_confused(min_val=5)

interp.plot_top_losses(9, figsize=(25,13))

###interp.plot_top_losses(4, figsize=(15,11))

interp.plot_confusion_matrix(figsize=(15,15), dpi=80)  # Larger figure with higher resolution

###interp.plot_confusion_matrix(figsize=(12,12), dpi=60)

"""### Unfreezing, fine-tuning, and learning rates

Since our model is working as we expect it to, we will unfreeze our model and train some more.

Single number (1-e3): every layer same lr

Discriminative learning rates, lr for the early layers is smaller, so it will move around less, because we think they are already good. Good for transfer learning.

Discriminative learning rates:
*   Single number to slice slice(1-e3) final layers get that lr. The other layers get the that lr/3
*   In this case slice(1-e5,1-e3), the last layers will have 1-e3, the first layer will get 1-e5 and the rest layers equally spread number between this two
"""

learn.unfreeze()

learn.lr_find(start_lr=1e-7, end_lr=1, num_it=100)

###learn.lr_find()
###learn.recorder.plot()

# Assuming `dls` is your DataLoaders object and `model_arch` is the architecture you are using.
from torchvision.models import resnet34

# Define your architecture
model_arch = resnet34

# Initialize the learner
learn = cnn_learner(dls, model_arch, metrics=accuracy)
learn.lr_find()  # find suitable learning rate
learn.fit_one_cycle(4, lr_max=slice(1e-5,1e-4))

###learn.fit_one_cycle(4, max_lr=slice(1e-5,1e-4))

learn.save('/content/drive/Shareddrives/T+ ML/Group_ML_T+2023/style/models/stage-2-resnet34')

###learn.save('stage-2-resnet34')
###print(learn)

os.listdir('/content/drive/Shareddrives/T+ ML/Group_ML_T+2023/style')

# learn = learn.load('stage-1-resnet34')

# learn.export()
# smaller size in case if no big differencce between resnet34 and resnet50

"""## Training: resnet50

Now we will train in the same way as before but instead of using resnet34 as our backbone we will use resnet50 (resnet34 is a 34 layer residual network while resnet50 has 50 layers. It will be explained later in the course and you can learn the details in the [resnet paper](https://arxiv.org/pdf/1512.03385.pdf)).

Basically, resnet50 usually performs better because it is a deeper network with more parameters. Let's see if we can achieve a higher performance here. To help it along, let's use larger images too, since that way the network can see more detail.

### Training
"""

from fastai.vision.all import *

path = '/content/drive/Shareddrives/T+ ML/Group_ML_T+2023/style'  # replace with your path
dls = ImageDataLoaders.from_folder(path, train=".", valid_pct=0.2,
                                   item_tfms=Resize(460),
                                   batch_tfms=[*aug_transforms(size=299), Normalize.from_stats(*imagenet_stats)],
                                   bs=64, num_workers=4)

###data = ImageDataBunch.from_folder(path, train=".", valid_pct=0.2,
        ###ds_tfms=tfms, size=299, num_workers=4, padding_mode='reflection', bs=64).normalize(imagenet_stats)

"""wd: weight decay
To avoid overfitting and still using a big amont of parameters. To make te function less complex,
"""

# learn = cnn_learner(data, models.resnet50, metrics=[accuracy, error_rate], wd=1e-1).to_fp16()
# there is no impovement with fp16

from fastai.vision.all import *  # ensure all necessary modules and functions are imported

learn = cnn_learner(dls, resnet50, metrics=[accuracy, error_rate], wd=1e-1)

###learn = cnn_learner(data, models.resnet50, metrics=[accuracy, error_rate], wd=1e-1)

learn.fit_one_cycle(6)

learn.save('stage-1-resnet50-6cycles')

"""### Unfreezing, fine-tuning and learning rates"""

learn.unfreeze()

# Find learning rate
learn.lr_find()

# If the plot is not automatically displayed or if you wish to save it:
fig = learn.recorder.plot_lr_find()
# fig.savefig('path_to_save_plot') # Uncomment and replace with the path to save the plot.

# Plotting Losses
learn.recorder.plot_loss()

###learn.lr_find()
###learn.recorder.plot()

learn.fit_one_cycle(6, lr_max=slice(1e-5,1e-4))

###learn.fit_one_cycle(6, max_lr=slice(1e-5,1e-4))

model_name = 'stage-2-resnet50'
learn.save(model_name)
model_path = learn.path/learn.model_dir/f'{model_name}.pth'
print(model_path)

###learn.save('stage-2-resnet50', return_path=True)

"""### Results resnet50"""

interp = ClassificationInterpretation.from_learner(learn)

interp.most_confused(min_val=3)

"""Duplicate images on top losses, because of data augmentation"""

interp.plot_confusion_matrix(figsize=(100,100), dpi=60)

interp.plot_top_losses(4, figsize=(15,11))

try:
    learn.show_results(nrows=4)  # Attempt to show results
except AttributeError as e:
    print(f"An error occurred: {e}")

learn.show_results(nrows=4)

from fastai.vision.all import PILImage

img_path = '/content/drive/Shareddrives/T+ ML/Group_ML_T+2023/style/train/Bauhaus architecture/46_800px-Friedrichshafen_Hafenbahnhof_Zeppelinmuseum.jpg'
img = PILImage.create(img_path)
img.show()  # To display the image.

###img = open_image(path/'arcDataset'/'Bauhaus architecture'/'46_800px-Friedrichshafen_Hafenbahnhof_Zeppelinmuseum.jpg')
# img

from fastai.vision.all import *

# Load data, setup model etc.
dls = ImageDataLoaders.from_folder('/content/drive/Shareddrives/T+ ML/Group_ML_T+2023/style')
learn = vision_learner(dls, resnet50, metrics=accuracy)

# Now, the `learn` object is defined, and you can call `predict` method on it.

pred_class, pred_idx, outputs = learn.predict(img)
class_names = dls.vocab

# Checking the type and value of pred_class
print(f"Type of pred_class: {type(pred_class)}, Value of pred_class: {pred_class}")

# If pred_class is expected to be an index, use pred_idx instead.
if isinstance(pred_idx, int) or (isinstance(pred_idx, torch.Tensor) and pred_idx.dim() == 0):
    print(class_names[pred_idx])
else:
    print("The prediction index is not valid.")

# Print the predicted class name directly
print(f"Predicted Class Name: {pred_class}")

# Print the index of the predicted class
print(f"Index of the Predicted Class: {pred_idx}")

# Ensuring that 'learn' is initialized and has the 'predict' method
if hasattr(learn, 'predict'):
    try:
        # Attempt to make a prediction on the provided 'img'
        pred_class, pred_idx, outputs = learn.predict(img)

        # Try to access the vocab (class names) from the DataLoader object
        try:
            class_names = dls.vocab  # Replace 'dls' with the correct variable name if different.
        except AttributeError:
            print("Error: Unable to access 'vocab' from 'dls'.")
        else:
            # If vocab is accessible, print the corresponding class name
            print(class_names[int(pred_class)])
    except Exception as e:
        print(f"Error: Unable to make a prediction due to {str(e)}")
else:
    print("Error: 'learn' object has no method 'predict'.")

print(f"Predicted Class Name: {pred_class}")
print(f"Index of the Predicted Class: {pred_idx}")
print(class_names[pred_idx])

###pred_class, pred_idx, outputs = learn.predict(img)
###class_names = dls.vocab  # Replace dls with the correct variable name if it's different.
###print(class_names[int(pred_class)])

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

# Assuming 'learn' is your Learner object, and 'img' is your image input.

# Ensure the 'learn' object exists and has the 'predict' method
if 'learn' in locals() and hasattr(learn, 'predict'):
    try:
        # Make a prediction
        pred_class, pred_idx, outputs = learn.predict(img)
    except Exception as e:
        print(f"Error: Unable to make a prediction due to {e}")
else:
    print("Error: 'learn' object is not defined or does not have the 'predict' method")

# Assuming 'dls' is your DataLoaders object; replace it with the actual variable name if different.
if 'dls' in locals() and hasattr(dls, 'vocab'):  # Replace 'vocab' with 'classes' or the correct attribute, if needed.
    try:
        # Print the predicted class name using the index
        print(dls.vocab[pred_idx])  # Replace 'vocab' with 'classes' or the correct attribute, if needed.
    except Exception as e:
        print(f"Error: Unable to access class names due to {e}")
else:
    print("Error: 'dls' object is not defined or does not have the 'vocab' attribute")

###pred_class,pred_idx,outputs = learn.predict(img)
###data.classes[int(pred_class)]

outputs

"""### RESNET 100"""

from fastai.vision.all import *

# Set the path to your image dataset
path = '/content/drive/Shareddrives/T+ ML/Group_ML_T+2023/style'

# Create an ImageDataLoaders object for your dataset
dls = ImageDataLoaders.from_folder(path, train=".", valid_pct=0.2,
                                   item_tfms=Resize(460),
                                   batch_tfms=[*aug_transforms(size=299), Normalize.from_stats(*imagenet_stats)],
                                   bs=32, num_workers=4)

# Define a ResNet-100 model and create a learner
from fastai.vision.all import *  # ensure all necessary modules and functions are imported
learn = vision_learner(dls, resnet101, metrics=[accuracy, error_rate], wd=1e-1)

import torch
torch.cuda.empty_cache()

# Train the model for a specified number of cycles
learn.fit_one_cycle(6)

learn.save('stage-1-resnet101-6cycles')

"""UNFREEZING"""

# Unfreeze the model to fine-tune it and find an appropriate learning rate
learn.unfreeze()

learn.lr_find()

# Plot the learning rate finder results
fig = learn.recorder.plot_lr_find()
# You can save the plot if needed: fig.savefig('path_to_save_plot')

# Plotting Losses
learn.recorder.plot_loss()

# Fine-tune the model with a suitable learning rate range
learn.fit_one_cycle(6, lr_max=slice(1e-5, 1e-4))

# Save the fine-tuned model
model_name = 'stage-2-resnet101'
learn.save(model_name)
model_path = learn.path / learn.model_dir / f'{model_name}.pth'
print(model_path)

"""RESULT OF RESNET100"""

# Create a ClassificationInterpretation object for model analysis
interp = ClassificationInterpretation.from_learner(learn)

# Analyze the most confused classes
interp.most_confused(min_val=3)

# Plot the confusion matrix
interp.plot_confusion_matrix(figsize=(12, 12), dpi=60)

# Plot the top losses
interp.plot_top_losses(4, figsize=(15, 11))

# Attempt to show some results
try:
    learn.show_results(nrows=4)
except AttributeError as e:
    print(f"An error occurred: {e}")

# Load an image for prediction
img_path = '/content/drive/Shareddrives/T+ ML/Group_ML_T+2023/style/train/Bauhaus architecture/46_800px-Friedrichshafen_Hafenbahnhof_Zeppelinmuseum.jpg'
img = PILImage.create(img_path)

# Make a prediction on the loaded image
pred_class, pred_idx, outputs = learn.predict(img)
class_names = dls.vocab

# Print the predicted class name and index
print(f"Predicted Class Name: {pred_class}")
print(f"Index of the Predicted Class: {pred_idx}")
print(class_names[pred_idx])

# Mount Google Drive if needed
from google.colab import drive
drive.mount('/content/drive', force_remount=True)

# Ensure the 'learn' object exists and has the 'predict' method
if 'learn' in locals() and hasattr(learn, 'predict'):
    try:
        # Make a prediction
        pred_class, pred_idx, outputs = learn.predict(img)
    except Exception as e:
        print(f"Error: Unable to make a prediction due to {e}")
else:
    print("Error: 'learn' object is not defined or does not have the 'predict' method")

# Assuming 'dls' is your DataLoaders object; replace it with the actual variable name if different.
if 'dls' in locals() and hasattr(dls, 'vocab'):
    try:
        # Print the predicted class name using the index
        print(dls.vocab[pred_idx])
    except Exception as e:
        print(f"Error: Unable to access class names due to {e}")
else:
    print("Error: 'dls' object is not defined or does not have the 'vocab' attribute")

# Print the 'outputs' if needed
print(outputs)

"""## Putting model in production

### Download model

Only the parameters are saved, not the actual architecture (so you'll need to create your model in the same way before loading weights back in)
"""

# Assuming 'learn' is your Learner object, and 'img' is your image input.

# Ensure the 'learn' object exists and has the 'predict' method
if 'learn' in locals() and hasattr(learn, 'predict'):
    try:
        # Make a prediction
        pred_class, pred_idx, outputs = learn.predict(img)
    except Exception as e:
        print(f"Error: Unable to make a prediction due to {e}")
else:
    print("Error: 'learn' object is not defined or does not have the 'predict' method")

# Assuming 'dls' is your DataLoaders object; replace it with the actual variable name if different.
if 'dls' in locals() and hasattr(dls, 'vocab'):  # Replace 'vocab' with 'classes' or the correct attribute, if needed.
    try:
        # Print the predicted class name using the index
        print(dls.vocab[pred_idx])  # Replace 'vocab' with 'classes' or the correct attribute, if needed.
    except Exception as e:
        print(f"Error: Unable to access class names due to {e}")
else:
    print("Error: 'dls' object is not defined or does not have the 'vocab' attribute")

###try:

###except Exception as e:
    ###print(f"An error occurred: {e}")

os.listdir('/content/drive/Shareddrives/T+ ML/Group_ML_T+2023/style/models')

from google.colab import drive
drive.mount('/content/mydrive', force_remount=True)

##cp "/content/drive/Shareddrives/T+ ML/Group_ML_T+2023/style/models/stage-2-resnet50.pth" "/path/to/content/drive/Shareddrives/T+ ML/Group_ML_T+2023/style/test"

cp "/content/mydrive/Shareddrives/T+ ML/Group_ML_T+2023/style/models/stage-2-resnet50.pth" "/content/mydrive/Shareddrives/T+ ML/Group_ML_T+2023/style/test"

import os
if os.path.exists('/content/mydrive/Shareddrives/T+ ML/Group_ML_T+2023/style/models/'):
    os.chdir('/content/mydrive/Shareddrives/T+ ML/Group_ML_T+2023/style/models/')
else:
    print("Directory does not exist. Please verify the path.")

import os
os.chdir('/content')

###cp /content/drive/Shareddrives/T+ ML/Group_ML_T+2023/style/models/299-resnet50.pth .

import os
import errno

try:
    os.listdir()
except Exception as e:
    if hasattr(e, 'errno') and e.errno == errno.ENOTCONN:
        print("The transport endpoint is not connected. Please check your mount points and network connection.")
    else:
        print(f"An error occurred: {e}")

try:
    os.listdir()
except Exception as e:
    print(f"An error occurred: {e}")

"""### Download to deploy model

To put model in production, export the minimal state of your Learner.
This will create a file named 'export.pkl' in the directory where we were working that contains everything we need to deploy our model (the model, the weights but also some metadata like the classes or the transforms/normalization used).
"""

learn.export('/content/drive/Shareddrives/T+ ML/Group_ML_T+2023/style/stage-1-resnet101-6cycles.pth')

###learn.export()

!ls "/content/drive/Shareddrives/T+ ML/Group_ML_T+2023/style/"

#from google.colab import files
#files.download('/root/.fastai/data/architecture/export.pkl')
!cp "/content/drive/Shareddrives/T+ ML/Group_ML_T+2023/style/export.pkl" .

#from google.colab import files
#files.download('/root/.fastai/data/architecture/export.pkl')
###!cp /root/.fastai/data/architecture/export.pkl .

# !rm /root/.fastai/data/architecture/export.pkl

# path of export.pkl
os.listdir('/content/drive/Shareddrives/T+ ML/Group_ML_T+2023/style/models')

"""## EXPORT TO THE SPECIFIC MODEL"""

from fastai.vision.all import *
import torch

# Define the path to your dataset and create DataLoaders
path = Path("/content/drive/Shareddrives/T+ ML/Group_ML_T+2023/style")
dls = ImageDataLoaders.from_folder(
    path,
    train=".",
    valid_pct=0.2,
    item_tfms=Resize(460),
    batch_tfms=[*aug_transforms(size=299), Normalize.from_stats(*imagenet_stats)],
    bs=64,
    num_workers=4
)

# Define your model architecture
model = cnn_learner(dls, resnet50, metrics=accuracy)

# Load the whole checkpoint
checkpoint_path = '/content/drive/Shareddrives/T+ ML/Group_ML_T+2023/style/models/stage-1-resnet101-6cycles.pth'
checkpoint = torch.load(checkpoint_path)

# Extract the state_dict of the model
model_state_dict = checkpoint.get('model', checkpoint)

# Try to load the model state_dict
try:
    model.model.load_state_dict(model_state_dict)
    print("Model state_dict loaded successfully!")
except RuntimeError as e:
    print(f"Error loading model state_dict: {e}")

# Export the Learner as .pkl file
export_path = path/'exported_model101.pkl'
model.export(export_path)
print(f"Model exported successfully to {export_path}")

from fastai.vision.all import *
import torch

# Define the path to your dataset and create DataLoaders
path = Path("/content/drive/Shareddrives/T+ ML/Group_ML_T+2023/style")
dls = ImageDataLoaders.from_folder(
    path,
    train=".",
    valid_pct=0.2,
    item_tfms=Resize(460),
    batch_tfms=[*aug_transforms(size=299), Normalize.from_stats(*imagenet_stats)],
    bs=64,
    num_workers=4
)

# Define your model architecture
model = cnn_learner(dls, resnet50, metrics=accuracy)

# Load the whole checkpoint
checkpoint_path = '/content/drive/Shareddrives/T+ ML/Group_ML_T+2023/style/models/stage-2-resnet101.pth'
checkpoint = torch.load(checkpoint_path)

# Extract the state_dict of the model
model_state_dict = checkpoint.get('model', checkpoint)

# Try to load the model state_dict
try:
    model.model.load_state_dict(model_state_dict)
    print("Model state_dict loaded successfully!")
except RuntimeError as e:
    print(f"Error loading model state_dict: {e}")

# Export the Learner as .pkl file
export_path = path/'exported_model101.pkl'
model.export(export_path)
print(f"Model exported successfully to {export_path}")

"""We create our `Learner` in production enviromnent like this, just make sure that `path` contains the file 'export.pkl' from before."""

!ls "/content/drive/Shareddrives/T+ ML/Group_ML_T+2023/style"

from fastai.vision.all import *
from google.colab import drive  # Only if using Google Colab and the file is in Google Drive

# Mount Google Drive (if using Google Colab)
drive.mount('/content/drive')

# Load the Image
img_path = '/content/drive/Shareddrives/T+ ML/Group_ML_T+2023/style/train/Gothic architecture/02_0130.jpg'
img = PILImage.create(img_path)

# Specify the full path to 'export.pkl' file
model_path = '/content/drive/Shareddrives/T+ ML/Group_ML_T+2023/style/exported_model101.pkl'
#model_path = '/content/drive/Shareddrives/T+ ML/Group_ML_T+2023/style/export.pkl'
# Then load the learner
learn = load_learner(model_path)

# Make a Prediction
pred_class, pred_idx, outputs = learn.predict(img)

# Print/Use the Predicted Class
#print(pred_class.obj)
# If pred_class is not a string
pred_class_str = str(pred_class)
pred_class,pred_idx,outputs = learn.predict(img)
print(str(pred_class))

###from pathlib import Path
###from fastai.vision.all import *

###path = Path('/content/drive/Shareddrives/T+ ML/Group_ML_T+2023/style/train')
###img = PILImage.create(path/'00000021.jpg')

###img = open_image(path/'black'/'00000021.jpg')
# img

###learn = load_learner('exported101.pkl')

###learn = load_learner(path)

pred_class,pred_idx,outputs = learn.predict(img)
print(str(pred_class))

###pred_class,pred_idx,outputs = learn.predict(img)
###pred_class.obj

"""## TEST WITH IMAGES"""

import os
import csv
from pathlib import Path
from fastai.vision.all import *
from PIL import Image

print("Current Working Directory: ", os.getcwd())

# Load the Learner
path = Path("/content/drive/Shareddrives/T+ ML/Group_ML_T+2023/style/")
learn = load_learner(path / 'exported_model101.pkl')

base_path = Path('/content/drive/Shareddrives/T+ ML/Group_ML_T+2023/testimg/5')
csv_file_path = '/content/drive/Shareddrives/T+ ML/Group_ML_T+2023/testimg/5/results_5_101.csv'  # replace with your desired path

try:
    with open(csv_file_path, 'w', newline='') as csv_file:
        writer = csv.writer(csv_file)
        writer.writerow(['FileName', 'PredictedClass'])

        print(f"Searching in {base_path}")  # Check if it is reaching here
        for item in base_path.glob('*'):
            print(f"Found {item}")  # Check each item found
            if item.is_dir():  # If the item is a directory, process image files in it
                for img_path in item.glob('*.*g'):
                    print(f"Found image {img_path}")  # Check each image found
                    # Process image files here...
            elif item.is_file() and item.suffix in ['.png', '.jpg', '.jpeg']:  # If the item is an image file, process it
                print(f"Found image {item}")  # Check each image found
                img = PILImage.create(item)
                img = img.resize((224, 224))
                pred_class, _, _ = learn.predict(img)
                writer.writerow([item.name, str(pred_class)])
                print(f"Image: {item.name} is predicted as class: {pred_class}")
            else:
                print(f"{item} is not a directory or an image file")
except Exception as e:
    print(f"An error occurred: {e}")

"""## Scrapping from google to valid dataset and valid test with google images

#### Upload model
"""

###uploaded = files.upload()

###uploaded = files.upload()

from fastai.vision.all import *
from fastai.vision.augment import aug_transforms

path = '/content/mydrive/Shareddrives/T+ ML/Group_ML_T+2023/style'

def is_cat(x): return x[0].isupper()

dls = ImageDataLoaders.from_name_func(
    path, get_image_files(path), valid_pct=0.2,
    label_func=is_cat, item_tfms=Resize(460),
    batch_tfms=aug_transforms(mult=2)
)

###np.random.seed(42)
###tfms = get_transforms(do_flip=True, flip_vert=False, max_rotate=10, max_zoom=1.1,
                      ###max_lighting=0.2, max_warp=0.2, p_affine=0.75, p_lighting=0.75)

###data = ImageDataBunch.from_folder(path, train=".", valid_pct=0.2,
        #ds_tfms=tfms, size=224, num_workers=4, padding_mode='reflection').normalize(imagenet_stats)

model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)

from fastai.vision.all import *

dls = ImageDataLoaders.from_folder('/content/mydrive/Shareddrives/T+ ML/Group_ML_T+2023/style')
learn = vision_learner(dls, resnet50, metrics=[accuracy])

###learn = cnn_learner(data, models.resnet50, metrics=[accuracy, error_rate], wd=1e-1)

os.mkdir('/content/drive/Shareddrives/T+ ML/Group_ML_T+2023/style/test2')

import os
full_path = os.path.abspath("stage-2-resnet50.pth")
print("Full Path: ", full_path)

from google.colab import drive
drive.flush_and_unmount()

from fastai.vision.all import *
from google.colab import drive  # Only if using Google Colab and the file is in Google Drive

# Mount Google Drive (if using Google Colab)
drive.mount('/content/drive')

drive.mount('/content/mydrive')

import os

if os.path.exists('tage-2-resnet50-deploy.pkl'):
    print("File exists")
else:
    print("File does not exist")

import os

# Print the current working directory
print("Current Working Directory:", os.getcwd())

# List the files in the current working directory
print("Files in Current Working Directory:", os.listdir())

import os
import shutil

# Change the current working directory
os.chdir('/content/drive/Shareddrives/T+ ML/Group_ML_T+2023/style/models')  # Replace with the actual path to your file

src = 'stage-2-resnet50.pth'
dst = '/content'

shutil.copy(src, dst)  # Copy the file
os.remove(src)  # Remove the original file

###models_dir = '/content/drive/Shareddrives/T+ ML/Group_ML_T+2023/style/models'
###os.rename('stage-2-resnet50.pth', models_dir + 'stage-2-resnet50.pth')

from fastai.vision.all import *
from PIL import Image

# Load the Learner
path = Path("/content/drive/Shareddrives/T+ ML/Group_ML_T+2023/style")
learn = load_learner(path / 'exported_model101.pkl')
print("Model Loaded Successfully")

# Load and transform the image
img_path = '/content/mydrive/Shareddrives/T+ ML/Group_ML_T+2023/style/valid/Gothic architecture/008637.jpg'

# Check if image is loaded properly
try:
    img = PILImage.create(img_path)
    print("Image Loaded Successfully")
except Exception as e:
    print(f"Error Loading Image: {e}")

# Resize the image and predict the class of the image
try:
    img = img.resize((224, 224))  # Replace 224 with the size your model expects
    print("Image Resized Successfully")
    pred_class, pred_idx, outputs = learn.predict(img)
    print(f"Predicted Class: {pred_class}")
except Exception as e:
    print(f"Error in Prediction: {e}")

# Display the predicted class
print(f'Predicted class: {pred_class}')

###from fastai.vision.all import *
###from PIL import Image
###import os
###import glob

# Load the Learner
###path_model = Path("/content/drive/Shareddrives/T+ ML/Group_ML_T+2023/style/models")
###learn = load_learner(path_model / 'export.pkl')

# Define the path where your folders with images are located
###base_path = Path('/content/drive/Shareddrives/T+ ML/Group_ML_T+2023/testimg')

# Loop over all folders and their subfolders and get all image files
###for folder in base_path.glob('*'):
    ###if folder.is_dir():
        ###for img_path in folder.glob('*.*g'):  # This will match .png, .jpg, .jpeg
            # Load and transform the image
            ###img = PILImage.create(img_path)
            ###img = img.resize((224, 224))  # Replace 224 with the size your model expects

            # Predict the class of the image
            ###pred_class, pred_idx, outputs = learn.predict(img)

            # Print the result
            ###print(f"Image: {img_path} is predicted as class: {pred_class}")

try:
    with open(csv_file_path, 'w', newline='') as csv_file:
        writer = csv.writer(csv_file)
        writer.writerow(['FileName', 'PredictedClass'])

        print(f"Searching in {base_path}")  # Check if it is reaching here
        for item in base_path.glob('*'):
            print(f"Found {item}")  # Check each item found
            if item.is_dir():  # If the item is a directory, process image files in it
                for img_path in item.glob('*.*g'):
                    print(f"Found image {img_path}")  # Check each image found
                    # Process image files here...
            elif item.is_file() and item.suffix in ['.png', '.jpg', '.jpeg']:  # If the item is an image file, process it
                print(f"Found image {item}")  # Check each image found
                img = PILImage.create(item)
                img = img.resize((224, 224))
                pred_class, _, _ = learn.predict(img)
                writer.writerow([item.name, str(pred_class)])
                print(f"Image: {item.name} is predicted as class: {pred_class}")
            else:
                print(f"{item} is not a directory or an image file")
except Exception as e:
    print(f"An error occurred: {e}")

# Assuming model is your trained model
num_classes = model.fc.out_features
print(num_classes)

print(model_state_dict.keys())

import os
import csv
from pathlib import Path
from fastai.vision.all import *
from PIL import Image

print("Current Working Directory: ", os.getcwd())

# Load the Learner
path = Path("/content/drive/Shareddrives/T+ ML/Group_ML_T+2023/style/")
learn = load_learner(path / 'exported_model101.pkl')

base_path = Path('/content/drive/Shareddrives/T+ ML/Group_ML_T+2023/testimg/paris facade')
csv_file_path = '/content/drive/Shareddrives/T+ ML/Group_ML_T+2023/testimg/paris facade/results_paris_101.csv'  # replace with your desired path

try:
    with open(csv_file_path, 'w', newline='') as csv_file:
        writer = csv.writer(csv_file)
        writer.writerow(['FileName', 'PredictedClass'])

        print(f"Searching in {base_path}")  # Check if it is reaching here
        for item in base_path.glob('*'):
            print(f"Found {item}")  # Check each item found
            if item.is_dir():  # If the item is a directory, process image files in it
                for img_path in item.glob('*.*g'):
                    print(f"Found image {img_path}")  # Check each image found
                    # Process image files here...
            elif item.is_file() and item.suffix in ['.png', '.jpg', '.jpeg']:  # If the item is an image file, process it
                print(f"Found image {item}")  # Check each image found
                img = PILImage.create(item)
                img = img.resize((224, 224))
                pred_class, _, _ = learn.predict(img)
                writer.writerow([item.name, str(pred_class)])
                print(f"Image: {item.name} is predicted as class: {pred_class}")
            else:
                print(f"{item} is not a directory or an image file")
except Exception as e:
    print(f"An error occurred: {e}")

import os
import csv
from pathlib import Path
from fastai.vision.all import *
from PIL import Image

print("Current Working Directory: ", os.getcwd())

# Load the Learner
path = Path("/content/drive/Shareddrives/T+ ML/Group_ML_T+2023/style/")
learn = load_learner(path / 'exported_model.pkl')

base_path = Path('/content/drive/Shareddrives/T+ ML/Group_ML_T+2023/testimg/5')
csv_file_path = '/content/drive/Shareddrives/T+ ML/Group_ML_T+2023/testimg/5/results_5_revised.csv'  # replace with your desired path

try:
    with open(csv_file_path, 'w', newline='') as csv_file:
        writer = csv.writer(csv_file)
        writer.writerow(['FileName', 'PredictedClass'])

        print(f"Searching in {base_path}")  # Check if it is reaching here
        for item in base_path.glob('*'):
            print(f"Found {item}")  # Check each item found
            if item.is_dir():  # If the item is a directory, process image files in it
                for img_path in item.glob('*.*g'):
                    print(f"Found image {img_path}")  # Check each image found
                    # Process image files here...
            elif item.is_file() and item.suffix in ['.png', '.jpg', '.jpeg']:  # If the item is an image file, process it
                print(f"Found image {item}")  # Check each image found
                img = PILImage.create(item)
                img = img.resize((224, 224))
                pred_class, _, _ = learn.predict(img)
                writer.writerow([item.name, str(pred_class)])
                print(f"Image: {item.name} is predicted as class: {pred_class}")
            else:
                print(f"{item} is not a directory or an image file")
except Exception as e:
    print(f"An error occurred: {e}")

import os
import csv
from pathlib import Path
from fastai.vision.all import *
from PIL import Image

print("Current Working Directory: ", os.getcwd())

# Load the Learner
path = Path("/content/drive/Shareddrives/T+ ML/Group_ML_T+2023/style/models")
learn = load_learner(path / 'export.pkl')

base_path = Path('/content/drive/Shareddrives/T+ ML/Group_ML_T+2023/bursa facade')
csv_file_path = '/content/drive/Shareddrives/T+ ML/Group_ML_T+2023/bursa facade/results_bursa.csv'  # replace with your desired path

try:
    with open(csv_file_path, 'w', newline='') as csv_file:
        writer = csv.writer(csv_file)
        writer.writerow(['FileName', 'PredictedClass'])

        print(f"Searching in {base_path}")  # Check if it is reaching here
        for item in base_path.glob('*'):
            print(f"Found {item}")  # Check each item found
            if item.is_dir():  # If the item is a directory, process image files in it
                for img_path in item.glob('*.*g'):
                    print(f"Found image {img_path}")  # Check each image found
                    # Process image files here...
            elif item.is_file() and item.suffix in ['.png', '.jpg', '.jpeg']:  # If the item is an image file, process it
                print(f"Found image {item}")  # Check each image found
                img = PILImage.create(item)
                img = img.resize((224, 224))
                pred_class, _, _ = learn.predict(img)
                writer.writerow([item.name, str(pred_class)])
                print(f"Image: {item.name} is predicted as class: {pred_class}")
            else:
                print(f"{item} is not a directory or an image file")
except Exception as e:
    print(f"An error occurred: {e}")

interp = ClassificationInterpretation.from_learner(learn)

interp.plot_confusion_matrix(figsize=(12,12), dpi=60)

"""### Download images from google"""

from imutils import paths
import argparse
import requests
import cv2

data.classes, data.c

os.mkdir("validation_test_2");

os.chdir('validation_test_2')

# Upload 25 files with from 47 to 49 urls of images of each architecture style
uploaded = files.upload()

os.listdir()

os.getcwd()

rows = {}

for filename in os.listdir():
  if filename.endswith(".txt"):
    rows[filename] = open(filename).read().strip().split("\n")

len(rows)

# import shutil
# shutil.rmtree('Queen Anne architecture')

"""Now you will need to download your images from their respective urls."""

num_images = 0
progress = 0
folders = data.c
validation_test_2 = {}

for arch_type in rows:
  os.mkdir(arch_type[:-4])
  os.rename(arch_type, arch_type[:-4] + '/' + arch_type)
  for url in rows[arch_type]:
    try:
      r = requests.get(url, timeout=60)
      # save the image to disk
      p = os.path.sep.join([arch_type[:-4], "{}.jpg".format(str(num_images).zfill(6))])
      f = open(p, "wb")
      f.write(r.content)
      f.close()
      num_images += 1

    except:
      print("[INFO] error downloading {}...skipping".format(p))

  progress += 1
  txt = "Progress: {} / {}"
  print(txt.format(progress, folders))
  validation_test_2[arch_type] = len(rows[arch_type])

num_images

"""Then we can remove any images that can't be opened"""

for c in classes:
    print(c)
    verify_images(path/c, delete=True, max_size=500)

"""#### View data"""

import numpy as np
import matplotlib.pyplot as plt

w=10
h=10
fig=plt.figure(figsize=(8, 8))
columns = 4
rows = 5
for i in range(1, columns*rows +1):
    num_img = ""
    if (i < 10):
      num_img = "0" + str(i)
    else:
      num_img = str(i)

    img = cv2.imread("Palladian architecture/0000" + num_img + ".jpg")
    img_cvt = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    fig.add_subplot(rows, columns, i)
    plt.imshow(img_cvt)
plt.show()

# ?open_image it is from fastai
# img = open_image('validation_test_2/00000047.jpg')
# img

"""### Prediction of google images

predictions:

*   [0]: folder === architecture style
*   [1]: pred_class (result)
*   [2]: pred_idx
*   [3]: outputs (percentatges)
*   [4]: error (1:error, 0:no error)
*   [5]: no valid image (1:no valid, 0:valid)
"""

img_analyzed = 0
predictions = [[0 for x in range(6)] for y in range(num_images)]
errors = 0
progress = 0
folders = data.c

for folder in os.listdir():
  for file in os.listdir(folder):
    try:
      if file.endswith(".jpg"):
        img = open_image(folder + '/' + file)
        pred_class,pred_idx,outputs = learn.predict(img)

        num_img = int(file[:-4])
        predictions[num_img][0] = folder
        predictions[num_img][1] = pred_class
        predictions[num_img][2] = pred_idx
        predictions[num_img][3] = outputs
        predictions[num_img][5] = 0

        if (folder != data.classes[int(pred_class)]):
          errors += 1
          predictions[num_img][4] = 1

        img_analyzed += 1

    except:
      print("ERROR ON: " + folder + " : " + file)


  progress += 1
  txt = "Progress: {} / {}"
  print(txt.format(progress, folders))


err_rate = errors/img_analyzed

# resnet50, size 299, bs 64, 6/6
# 299
print(errors)
err_rate

"""### Cleaning up

Some of our top losses aren't due to bad performance by our model. There are images in our data set that shouldn't be.
"""

# Commented out IPython magic to ensure Python compatibility.
# %pylab inline
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from IPython.display import clear_output

errors_i = 0
for i in range(len(predictions)):
  if predictions[i][4] == 1:
    errors_i += 1
    txt = "Progress: {} / {}"
    print(txt.format(errors_i, errors))
    print(predictions[i][0] + '\n' + data.classes[int(predictions[i][1])])

    filename = str(i).zfill(6) + '.jpg'
    img=mpimg.imread(predictions[i][0] + '/' + filename)
    imgplot = plt.imshow(img)
    plt.show()

    time.sleep(3)
    clear_output(wait=True)

errors2 = 0
num_not_valid = 0
# folder_mal = {"nada"}

print("Not Valid? 1:No Valid, 0: Valid")

for i in range(len(predictions)):
  txt = "Progress: {} / {}"
  print(txt.format(i, len(predictions)))

  if predictions[i][4] == 1:
    filename = str(i).zfill(6) + '.jpg'
    print(predictions[i][0] + '/' + data.classes[int(predictions[i][1])])
    img=mpimg.imread(predictions[i][0] + '/' + filename)
    imgplot = plt.imshow(img)
    plt.show()
    not_valid = input()

    if not_valid == 1:
      predictions[i][5] = 1
      num_not_valid += 1
    else:
      errors2 += 1
    clear_output(wait=True)
    # folder_mal.add(predictions[i][0])

num_not_valid
# len(folder_mal)

"""## Useful Commands"""

# Check GPU specifications
from tensorflow.python.client import device_lib
device_lib.list_local_devices()

# Check CPU and RAM specifications
!cat /proc/cpuinfo
!cat /proc/meminfo

# Cloning a git repository
!git clone [git clone url]

# Download from the web to colab disk (temporal)
!wget 'https://images-na.ssl-images-amazon.com/images/I/91GG851w5EL.jpg'

# Download from the web to your Drive
!wget [url] -p drive/[Folder Name]

# https://medium.com/lean-in-women-in-tech-india/google-colab-the-beginners-guide-5ad3b417dfa
# Mounting Google Drive
!apt-get install -y -qq software-properties-common python-software-properties module-init-tools
!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null
!apt-get update -qq 2>&1 > /dev/null
!apt-get -y install -qq google-drive-ocamlfuse fuse
from google.colab import auth
auth.authenticate_user()
from oauth2client.client import GoogleCredentials
creds = GoogleCredentials.get_application_default()
import getpass
!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL
vcode = getpass.getpass()
!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}

# Click on the link and enter the api key.

!mkdir -p drive
!google-drive-ocamlfuse drive

# Your drive is now mounted. You can use any files and folders in your drive by using the path as follows
!ls /content/drive/[folder name]